"""
ä»·æ ¼é¢„æµ‹ç½‘ç»œç‹¬ç«‹è®­ç»ƒè„šæœ¬
ä¸“é—¨è®­ç»ƒTransformeræ¶æ„çš„ä»·æ ¼é¢„æµ‹æ¨¡å‹
"""

import sys
import os
sys.path.append('src')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

from price_prediction.config import PricePredictionConfigs
from price_prediction.data_processor import PricePredictionDataProcessor
from price_prediction.price_transformer import PriceTransformer

def create_dataloader(features, targets, batch_size, shuffle=True):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    dataset = TensorDataset(features, targets)
    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)

def train_price_prediction_model(config):
    """è®­ç»ƒä»·æ ¼é¢„æµ‹æ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒä»·æ ¼é¢„æµ‹æ¨¡å‹")
    print("="*50)
    
    # 1. åˆ›å»ºæ•°æ®å¤„ç†å™¨
    print("ğŸ“Š åŠ è½½æ•°æ®...")
    data_processor = PricePredictionDataProcessor(
        data_dir=config.data_dir,
        sequence_length=config.sequence_length,
        prediction_horizon=config.prediction_horizon,
        large_value_transform=config.large_value_transform
    )
    
    # 2. åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    stock_data = data_processor.load_all_stocks_for_price_prediction()
    
    if not stock_data:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®")
        return None
    
    # 3. åˆå¹¶æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    all_features = []
    all_targets = []
    
    for stock_name, (features, targets) in stock_data.items():
        all_features.append(features)
        all_targets.append(targets)
        print(f"  {stock_name}: {features.shape[0]} ä¸ªåºåˆ—")
    
    # åˆå¹¶æ•°æ®
    train_features = torch.cat(all_features, dim=0)
    train_targets = torch.cat(all_targets, dim=0)
    
    print(f"\nğŸ“ˆ è®­ç»ƒæ•°æ®ç»Ÿè®¡:")
    print(f"  ç‰¹å¾å½¢çŠ¶: {train_features.shape}")
    print(f"  ç›®æ ‡å½¢çŠ¶: {train_targets.shape}")
    print(f"  æ€»åºåˆ—æ•°: {len(train_features)}")
    
    # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = create_dataloader(train_features, train_targets, config.batch_size)
    
    # 5. åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹...")
    model = PriceTransformer(config)
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  æ€»å‚æ•°æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # 6. è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )
    
    if config.loss_type == "mse":
        criterion = nn.MSELoss()
    elif config.loss_type == "mae":
        criterion = nn.L1Loss()
    elif config.loss_type == "huber":
        criterion = nn.HuberLoss(delta=config.huber_delta)
    else:
        criterion = nn.MSELoss()
    
    # 7. è®­ç»ƒå¾ªç¯
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    train_losses = []
    best_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(config.max_epochs):
        model.train()
        epoch_losses = []
        
        # è®­ç»ƒä¸€ä¸ªepoch
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.max_epochs}")
        for batch_idx, (features, targets) in enumerate(pbar):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = model(features)
            price_predictions = outputs['price_predictions']
            
            # è®¡ç®—æŸå¤±
            loss = criterion(price_predictions, targets)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            epoch_losses.append(loss.item())
            pbar.set_postfix({'loss': f'{loss.item():.6f}'})
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = np.mean(epoch_losses)
        train_losses.append(avg_loss)
        
        print(f"Epoch {epoch+1}: å¹³å‡æŸå¤± = {avg_loss:.6f}")
        
        # æ—©åœæ£€æŸ¥
        if avg_loss < best_loss:
            best_loss = avg_loss
            patience_counter = 0
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            os.makedirs(config.save_dir, exist_ok=True)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': best_loss,
                'config': config
            }, os.path.join(config.save_dir, 'best_price_model.pth'))
            
        else:
            patience_counter += 1
            if patience_counter >= config.early_stopping_patience:
                print(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                break
        
        # å®šæœŸä¿å­˜
        if (epoch + 1) % config.save_every_n_epochs == 0:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_loss,
                'config': config
            }, os.path.join(config.save_dir, f'price_model_epoch_{epoch+1}.pth'))
    
    # 8. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('ä»·æ ¼é¢„æµ‹æ¨¡å‹è®­ç»ƒæ›²çº¿')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(config.save_dir, 'training_curve.png'))
    plt.show()
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³æŸå¤±: {best_loss:.6f}")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {config.save_dir}")
    
    return model, train_losses

def main():
    """ä¸»å‡½æ•°"""
    # é€‰æ‹©é…ç½®
    print("é€‰æ‹©æ¨¡å‹é…ç½®:")
    print("1. tiny - è½»é‡çº§æµ‹è¯•")
    print("2. small - å°å‹æ¨¡å‹")
    print("3. base - åŸºç¡€æ¨¡å‹ï¼ˆæ¨èï¼‰")
    print("4. large - å¤§å‹æ¨¡å‹")
    print("5. long_sequence - é•¿åºåˆ—ä¸“ç”¨")
    
    choice = input("è¯·é€‰æ‹©é…ç½® (1-5, é»˜è®¤3): ").strip() or "3"
    
    config_map = {
        "1": PricePredictionConfigs.tiny(),
        "2": PricePredictionConfigs.small(),
        "3": PricePredictionConfigs.base(),
        "4": PricePredictionConfigs.large(),
        "5": PricePredictionConfigs.for_long_sequence()
    }
    
    config = config_map.get(choice, PricePredictionConfigs.base())
    
    # å¼€å§‹è®­ç»ƒ
    try:
        model, losses = train_price_prediction_model(config)
        
        if model is not None:
            print("\nğŸ‰ ä»·æ ¼é¢„æµ‹æ¨¡å‹è®­ç»ƒæˆåŠŸ!")
            print("ç°åœ¨å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œä»·æ ¼é¢„æµ‹äº†ã€‚")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
