#!/usr/bin/env python3
"""
ä»·æ ¼é¢„æµ‹ç½‘ç»œè®­ç»ƒè„šæœ¬
ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒTransformerä»·æ ¼é¢„æµ‹ç½‘ç»œ
"""

import torch
import torch.optim as optim
import numpy as np
import sys
import os
from typing import Dict, Any

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import ModelConfigs
from price_prediction.price_transformer import PriceTransformer, PricePredictionLoss
from financial_data import FinancialDataProcessor, create_sample_data


def create_price_dataset():
    """åˆ›å»ºä»·æ ¼é¢„æµ‹æ•°æ®é›†"""
    print("ğŸ”„ åˆ›å»ºä»·æ ¼é¢„æµ‹æ•°æ®...")
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    sample_data = create_sample_data(n_days=800)  # æ›´å¤šæ•°æ®ç”¨äºä»·æ ¼é¢„æµ‹è®­ç»ƒ
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = "temp_price_data.txt"
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(sample_data)
    
    # å¤„ç†æ•°æ®
    processor = FinancialDataProcessor(
        sequence_length=180,
        prediction_horizon=7,
        trading_horizon=1,  # ä»·æ ¼é¢„æµ‹ä¸éœ€è¦äº¤æ˜“åºåˆ—
        normalize=True,
        enable_trading_strategy=False,  # åªåšä»·æ ¼é¢„æµ‹
        sliding_window=False
    )
    
    # è¯»å–å¹¶å¤„ç†æ•°æ®
    with open(temp_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    data_list = []
    for line in lines:
        if line.strip():
            parsed = processor.parse_data_line(line)
            if parsed:
                data_list.append(parsed)
    
    if not data_list:
        raise ValueError("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•æ•°æ®")
    
    # è½¬æ¢ä¸ºDataFrame
    import pandas as pd
    df = pd.DataFrame(data_list)
    df = processor.add_time_encoding(df)
    processor.fit_normalizer(df)
    df = processor.normalize_features(df)
    
    # åˆ›å»ºä»·æ ¼é¢„æµ‹åºåˆ—
    features_list, price_targets_list = processor.create_price_prediction_sequences(df)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_file)
    
    return features_list, price_targets_list, processor


def create_price_batches(features_list, price_targets_list, batch_size=8):
    """åˆ›å»ºä»·æ ¼é¢„æµ‹æ‰¹æ¬¡"""
    n_samples = len(features_list)
    batches = []
    
    for i in range(0, n_samples, batch_size):
        end_idx = min(i + batch_size, n_samples)
        
        batch_features = torch.stack(features_list[i:end_idx])
        batch_targets = torch.stack(price_targets_list[i:end_idx])
        
        batches.append({
            'features': batch_features,
            'price_targets': batch_targets
        })
    
    return batches


def train_price_network():
    """è®­ç»ƒä»·æ ¼é¢„æµ‹ç½‘ç»œ"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒä»·æ ¼é¢„æµ‹ç½‘ç»œ...")
    print("ğŸ’¡ ç›®æ ‡: ä¸“é—¨ä¼˜åŒ–ä»·æ ¼é¢„æµ‹èƒ½åŠ›")
    
    # 1. åˆ›å»ºæ•°æ®
    features_list, price_targets_list, processor = create_price_dataset()
    
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶:")
    print(f"  - ç‰¹å¾æ•°é‡: {len(features_list)}")
    print(f"  - ç‰¹å¾ç»´åº¦: {features_list[0].shape}")      # [180, 11]
    print(f"  - ä»·æ ¼ç›®æ ‡: {price_targets_list[0].shape}")  # [7]
    
    # 2. æ•°æ®åˆ†å‰²
    n_samples = len(features_list)
    train_size = int(0.8 * n_samples)
    
    train_features = features_list[:train_size]
    train_targets = price_targets_list[:train_size]
    
    val_features = features_list[train_size:]
    val_targets = price_targets_list[train_size:]
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"  - è®­ç»ƒæ ·æœ¬: {len(train_features)} ä¸ª")
    print(f"  - éªŒè¯æ ·æœ¬: {len(val_features)} ä¸ª")
    
    # 3. åˆ›å»ºæ‰¹æ¬¡
    batch_size = 8
    train_batches = create_price_batches(train_features, train_targets, batch_size)
    val_batches = create_price_batches(val_features, val_targets, batch_size)
    
    print(f"ğŸ“Š æ‰¹æ¬¡ä¿¡æ¯:")
    print(f"  - è®­ç»ƒæ‰¹æ¬¡: {len(train_batches)} ä¸ª")
    print(f"  - éªŒè¯æ‰¹æ¬¡: {len(val_batches)} ä¸ª")
    
    # 4. åˆ›å»ºæ¨¡å‹
    config = ModelConfigs.small()  # ä»·æ ¼é¢„æµ‹å¯ä»¥ç”¨ç¨å¤§çš„æ¨¡å‹
    
    model = PriceTransformer(config)
    loss_fn = PricePredictionLoss(loss_type='mse')
    
    print(f"ğŸ—ï¸ ä»·æ ¼é¢„æµ‹æ¨¡å‹:")
    print(f"  - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"  - æ¨¡å‹ç»´åº¦: {config.d_model}")
    print(f"  - å±‚æ•°: {config.n_layers}")
    print(f"  - æ³¨æ„åŠ›å¤´æ•°: {config.n_heads}")
    
    # 5. è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay,
        betas=(config.beta1, config.beta2)
    )
    
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=30, eta_min=1e-6
    )
    
    # 6. è®­ç»ƒå¾ªç¯
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    print("ğŸ“ˆ å¼€å§‹ä»·æ ¼é¢„æµ‹è®­ç»ƒ...")
    
    num_epochs = 30
    best_val_loss = float('inf')
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_mae = 0.0
        train_direction_acc = 0.0
        
        for batch_idx, batch_data in enumerate(train_batches):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            features = batch_data['features'].to(device)
            targets = batch_data['price_targets'].to(device)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = model(features, return_features=False, return_dict=True)
            predictions = outputs['price_predictions']
            
            # è®¡ç®—æŸå¤±
            loss_dict = loss_fn(predictions, targets)
            loss = loss_dict['loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            # ç´¯ç§¯æŒ‡æ ‡
            train_loss += loss.item()
            train_mae += loss_dict['mae']
            train_direction_acc += loss_dict['direction_accuracy']
            
            # æ‰“å°è¿›åº¦
            if (batch_idx + 1) % 20 == 0:
                print(f"  Batch {batch_idx+1}/{len(train_batches)}: "
                      f"Loss={loss.item():.6f}, "
                      f"MAE={loss_dict['mae']:.6f}, "
                      f"DirAcc={loss_dict['direction_accuracy']:.4f}")
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_mae = 0.0
        val_direction_acc = 0.0
        
        with torch.no_grad():
            for batch_data in val_batches:
                features = batch_data['features'].to(device)
                targets = batch_data['price_targets'].to(device)
                
                outputs = model(features, return_features=False, return_dict=True)
                predictions = outputs['price_predictions']
                
                loss_dict = loss_fn(predictions, targets)
                
                val_loss += loss_dict['loss'].item()
                val_mae += loss_dict['mae']
                val_direction_acc += loss_dict['direction_accuracy']
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        train_loss /= len(train_batches)
        train_mae /= len(train_batches)
        train_direction_acc /= len(train_batches)
        
        val_loss /= len(val_batches)
        val_mae /= len(val_batches)
        val_direction_acc /= len(val_batches)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'model_state_dict': model.state_dict(),
                'config': config,
                'epoch': epoch,
                'val_loss': val_loss
            }, 'best_price_network.pth')
        
        # æ‰“å°epochç»“æœ
        print(f"\nEpoch {epoch+1:2d}/{num_epochs}:")
        print(f"  è®­ç»ƒ - æŸå¤±: {train_loss:.6f}, MAE: {train_mae:.6f}, æ–¹å‘å‡†ç¡®ç‡: {train_direction_acc:.4f}")
        print(f"  éªŒè¯ - æŸå¤±: {val_loss:.6f}, MAE: {val_mae:.6f}, æ–¹å‘å‡†ç¡®ç‡: {val_direction_acc:.4f}")
        print(f"  å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.2e}")
    
    print("âœ… ä»·æ ¼é¢„æµ‹ç½‘ç»œè®­ç»ƒå®Œæˆ!")
    
    # 7. æµ‹è¯•æœ€ä½³æ¨¡å‹
    print("\nğŸ”® æµ‹è¯•æœ€ä½³ä»·æ ¼é¢„æµ‹æ¨¡å‹...")
    checkpoint = torch.load('best_price_network.pth')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # ä½¿ç”¨ä¸€ä¸ªéªŒè¯æ‰¹æ¬¡è¿›è¡Œæµ‹è¯•
    if val_batches:
        test_batch = val_batches[0]
        features = test_batch['features'].to(device)
        targets = test_batch['price_targets'].to(device)
        
        with torch.no_grad():
            outputs = model(features, return_features=True, return_dict=True)
            predictions = outputs['price_predictions']
            features_extracted = outputs['strategy_features']
            
            loss_dict = loss_fn(predictions, targets)
            
            print(f"ğŸ“Š æœ€ä½³æ¨¡å‹æ€§èƒ½:")
            print(f"  - é¢„æµ‹æŸå¤±: {loss_dict['loss']:.6f}")
            print(f"  - å¹³å‡ç»å¯¹è¯¯å·®: {loss_dict['mae']:.6f}")
            print(f"  - ç›¸å¯¹è¯¯å·®: {loss_dict['relative_error']:.4f}")
            print(f"  - æ–¹å‘å‡†ç¡®ç‡: {loss_dict['direction_accuracy']:.4f}")
            print(f"  - æå–ç‰¹å¾ç»´åº¦: {features_extracted.shape}")
            
            # æ˜¾ç¤ºä¸€ä¸ªé¢„æµ‹ç¤ºä¾‹
            sample_pred = predictions[0].cpu().numpy()
            sample_target = targets[0].cpu().numpy()
            
            print(f"\nğŸ“ˆ é¢„æµ‹ç¤ºä¾‹:")
            print(f"  é¢„æµ‹ä»·æ ¼: {sample_pred}")
            print(f"  çœŸå®ä»·æ ¼: {sample_target}")
            print(f"  é¢„æµ‹è¯¯å·®: {sample_pred - sample_target}")
    
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: best_price_network.pth")
    print(f"ğŸ“‹ ä¸‹ä¸€æ­¥: è¿è¡Œ python train_strategy_network.py è®­ç»ƒç­–ç•¥ç½‘ç»œ")


if __name__ == "__main__":
    train_price_network()
