#!/usr/bin/env python3
"""
æ»‘åŠ¨çª—å£é‡‘èé‡åŒ–æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import sys
import os
from typing import Tuple

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import ModelArgs, ModelConfigs
from transformer import FinancialTransformer
from financial_data import FinancialDataProcessor, create_sample_data


def create_sliding_window_dataset() -> Tuple[torch.Tensor, ...]:
    """åˆ›å»ºæ»‘åŠ¨çª—å£æ•°æ®é›†"""
    print("ğŸ”„ åˆ›å»ºæ»‘åŠ¨çª—å£é‡‘èæ•°æ®...")
    
    # ç”Ÿæˆæ›´é•¿çš„ç¤ºä¾‹æ•°æ®ï¼ˆè‡³å°‘207å¤©ï¼š180+20+7ï¼‰
    sample_data = create_sample_data(n_days=500)
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = "temp_sliding_window_data.txt"
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(sample_data)
    
    # å¤„ç†æ•°æ®
    processor = FinancialDataProcessor(
        sequence_length=180,  # ä½¿ç”¨180å¤©å†å²æ•°æ®
        prediction_horizon=7,  # é¢„æµ‹7å¤©ä»·æ ¼
        trading_horizon=20,    # 20å¤©æ»‘åŠ¨çª—å£
        normalize=True,
        enable_trading_strategy=True,
        sliding_window=True
    )
    
    # è¯»å–å¹¶å¤„ç†æ•°æ®
    with open(temp_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    data_list = []
    for line in lines:
        if line.strip():
            parsed = processor.parse_data_line(line)
            if parsed:
                data_list.append(parsed)
    
    if not data_list:
        raise ValueError("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•æ•°æ®")
    
    # è½¬æ¢ä¸ºDataFrame
    import pandas as pd
    df = pd.DataFrame(data_list)
    
    # æ·»åŠ æ—¶é—´ç¼–ç 
    df = processor.add_time_encoding(df)
    
    # è®¡ç®—æ ‡å‡†åŒ–å‚æ•°
    processor.fit_normalizer(df)
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    df = processor.normalize_features(df)
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£åºåˆ—
    data_outputs = processor.create_sliding_window_sequences(df)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_file)
    
    return data_outputs + (processor,)


def train_sliding_window_model():
    """è®­ç»ƒæ»‘åŠ¨çª—å£æ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ»‘åŠ¨çª—å£é‡‘èé‡åŒ–æ¨¡å‹...")
    
    # 1. åˆ›å»ºæ•°æ®
    features_list, price_targets_list, position_targets, next_day_returns, processor = create_sliding_window_dataset()
    
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶:")
    print(f"  - ç‰¹å¾åºåˆ—: {features_list.shape}")  # [n_sequences, 20, 180, 11]
    print(f"  - ä»·æ ¼ç›®æ ‡: {price_targets_list.shape}")  # [n_sequences, 20, 7]
    print(f"  - ä»“ä½ç›®æ ‡: {position_targets.shape}")  # [n_sequences, 20]
    print(f"  - æ¬¡æ—¥æ”¶ç›Š: {next_day_returns.shape}")  # [n_sequences, 20]
    
    # 2. é‡æ–°ç»„ç»‡æ•°æ®ç”¨äºè®­ç»ƒ
    # å°† [n_sequences, 20, ...] å±•å¹³ä¸º [n_sequences*20, ...]
    n_sequences, n_slides = features_list.shape[:2]
    
    # å±•å¹³ç‰¹å¾æ•°æ®
    features_flat = features_list.view(-1, features_list.shape[2], features_list.shape[3])  # [n_sequences*20, 180, 11]
    price_targets_flat = price_targets_list.view(-1, price_targets_list.shape[2])  # [n_sequences*20, 7]
    next_day_returns_flat = next_day_returns.view(-1)  # [n_sequences*20]
    
    print(f"ğŸ“Š å±•å¹³åæ•°æ®å½¢çŠ¶:")
    print(f"  - ç‰¹å¾: {features_flat.shape}")
    print(f"  - ä»·æ ¼ç›®æ ‡: {price_targets_flat.shape}")
    print(f"  - æ¬¡æ—¥æ”¶ç›Š: {next_day_returns_flat.shape}")
    
    # 3. æ•°æ®åˆ†å‰²
    train_size = int(0.8 * len(features_flat))
    train_features = features_flat[:train_size]
    train_price_targets = price_targets_flat[:train_size]
    train_returns = next_day_returns_flat[:train_size]
    
    val_features = features_flat[train_size:]
    val_price_targets = price_targets_flat[train_size:]
    val_returns = next_day_returns_flat[train_size:]
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"  - è®­ç»ƒé›†: {len(train_features)} æ ·æœ¬")
    print(f"  - éªŒè¯é›†: {len(val_features)} æ ·æœ¬")
    
    # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(train_features, train_price_targets, train_returns)
    val_dataset = TensorDataset(val_features, val_price_targets, val_returns)
    
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # 5. åˆ›å»ºæ¨¡å‹
    config = ModelConfigs.tiny()  # ä½¿ç”¨å°æ¨¡å‹è¿›è¡Œæµ‹è¯•
    model = FinancialTransformer(config)
    
    print(f"ğŸ—ï¸ æ¨¡å‹åˆ›å»ºå®Œæˆ:")
    print(f"  - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"  - è¾“å…¥ç‰¹å¾: {config.n_features}")
    print(f"  - ä»·æ ¼é¢„æµ‹: {config.n_predictions}")
    print(f"  - ä»“ä½é¢„æµ‹: å¯ç”¨")
    
    # 6. è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay,
        betas=(config.beta1, config.beta2)
    )
    
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=50, eta_min=1e-6
    )
    
    # 7. è®­ç»ƒå¾ªç¯
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    print("ğŸ“ˆ å¼€å§‹è®­ç»ƒ...")
    
    num_epochs = 30
    best_val_loss = float('inf')
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_price_loss = 0.0
        train_position_loss = 0.0
        train_batches = 0
        
        for batch_features, batch_price_targets, batch_returns in train_loader:
            batch_features = batch_features.to(device)
            batch_price_targets = batch_price_targets.to(device)
            batch_returns = batch_returns.to(device)
            
            optimizer.zero_grad()
            
            outputs = model(
                financial_data=batch_features,
                target_prices=batch_price_targets,
                next_day_returns=batch_returns,
                return_dict=True
            )
            
            loss = outputs['loss']
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            train_loss += loss.item()
            if outputs.get('price_loss') is not None:
                train_price_loss += outputs['price_loss'].item()
            if outputs.get('position_loss') is not None:
                train_position_loss += outputs['position_loss'].item()
            train_batches += 1
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_price_loss = 0.0
        val_position_loss = 0.0
        val_batches = 0
        
        with torch.no_grad():
            for batch_features, batch_price_targets, batch_returns in val_loader:
                batch_features = batch_features.to(device)
                batch_price_targets = batch_price_targets.to(device)
                batch_returns = batch_returns.to(device)
                
                outputs = model(
                    financial_data=batch_features,
                    target_prices=batch_price_targets,
                    next_day_returns=batch_returns,
                    return_dict=True
                )
                
                val_loss += outputs['loss'].item()
                if outputs.get('price_loss') is not None:
                    val_price_loss += outputs['price_loss'].item()
                if outputs.get('position_loss') is not None:
                    val_position_loss += outputs['position_loss'].item()
                val_batches += 1
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_train_loss = train_loss / train_batches
        avg_val_loss = val_loss / val_batches
        avg_train_price_loss = train_price_loss / train_batches if train_batches > 0 else 0
        avg_train_position_loss = train_position_loss / train_batches if train_batches > 0 else 0
        avg_val_price_loss = val_price_loss / val_batches if val_batches > 0 else 0
        avg_val_position_loss = val_position_loss / val_batches if val_batches > 0 else 0
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), 'best_sliding_window_model.pth')
        
        # æ‰“å°è¿›åº¦
        print(f"Epoch {epoch+1:2d}/{num_epochs} | "
              f"Loss: {avg_train_loss:.6f}/{avg_val_loss:.6f} | "
              f"Price: {avg_train_price_loss:.6f}/{avg_val_price_loss:.6f} | "
              f"Position: {avg_train_position_loss:.6f}/{avg_val_position_loss:.6f} | "
              f"LR: {scheduler.get_last_lr()[0]:.2e}")
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    
    # 8. æµ‹è¯•é¢„æµ‹
    print("\nğŸ”® æµ‹è¯•æ»‘åŠ¨çª—å£é¢„æµ‹åŠŸèƒ½...")
    model.eval()
    
    # ä½¿ç”¨éªŒè¯é›†çš„ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
    test_features = val_features[:1].to(device)
    test_price_targets = val_price_targets[:1].to(device)
    test_returns = val_returns[:1].to(device)
    
    with torch.no_grad():
        predictions = model.predict(test_features, return_dict=True)
        
        # ä»·æ ¼é¢„æµ‹
        predicted_prices = predictions['price_predictions']
        predicted_prices_denorm = processor.denormalize_predictions(predicted_prices)
        actual_prices_denorm = processor.denormalize_predictions(test_price_targets)
        
        print(f"ğŸ“Š ä»·æ ¼é¢„æµ‹ç»“æœ:")
        print(f"  å®é™…ä»·æ ¼: {actual_prices_denorm[0].cpu().numpy()}")
        print(f"  é¢„æµ‹ä»·æ ¼: {predicted_prices_denorm[0].cpu().numpy()}")
        
        # ä»“ä½é¢„æµ‹
        if 'position_predictions' in predictions:
            position_pred = predictions['position_predictions']
            print(f"\nğŸ“ˆ ä»“ä½é¢„æµ‹ç»“æœ:")
            print(f"  é¢„æµ‹ä»“ä½: {position_pred[0].item():.2f} (0-10)")
            print(f"  æ¬¡æ—¥æ”¶ç›Š: {test_returns[0].item():.4f} ({test_returns[0].item()*100:.2f}%)")
            
            # è®¡ç®—è¯¥ä»“ä½çš„æ”¶ç›Š
            position_return = position_pred[0].item() * test_returns[0].item()
            print(f"  ä»“ä½æ”¶ç›Š: {position_return:.4f} ({position_return*100:.2f}%)")


if __name__ == "__main__":
    train_sliding_window_model()
