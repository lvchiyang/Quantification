#!/usr/bin/env python3
"""
ç­–ç•¥ç½‘ç»œè®­ç»ƒè„šæœ¬
ç¬¬äºŒé˜¶æ®µï¼šåŸºäºé¢„è®­ç»ƒçš„ä»·æ ¼ç½‘ç»œï¼Œè®­ç»ƒGRUç­–ç•¥ç½‘ç»œ
"""

import torch
import torch.optim as optim
import numpy as np
import sys
import os
from typing import Dict, Any

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import ModelConfigs
from price_prediction.price_transformer import PriceTransformer
from strategy_network.gru_strategy import GRUStrategyNetwork
from strategy_network.strategy_loss import StrategyLoss
from strategy_network.strategy_trainer import StrategyTrainingPipeline, create_strategy_batches
from financial_data import FinancialDataProcessor, create_sample_data
from market_classifier import create_market_classifier


def load_pretrained_price_network(checkpoint_path: str) -> PriceTransformer:
    """åŠ è½½é¢„è®­ç»ƒçš„ä»·æ ¼ç½‘ç»œ"""
    print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒä»·æ ¼ç½‘ç»œ: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ä»·æ ¼ç½‘ç»œæ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    config = checkpoint['config']
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    price_network = PriceTransformer(config)
    price_network.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"âœ… ä»·æ ¼ç½‘ç»œåŠ è½½æˆåŠŸ (Epoch {checkpoint['epoch']}, Val Loss: {checkpoint['val_loss']:.6f})")
    
    return price_network, config


def create_strategy_dataset():
    """åˆ›å»ºç­–ç•¥è®­ç»ƒæ•°æ®é›†"""
    print("ğŸ”„ åˆ›å»ºç­–ç•¥è®­ç»ƒæ•°æ®...")
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    sample_data = create_sample_data(n_days=600)  # ç­–ç•¥è®­ç»ƒæ•°æ®
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = "temp_strategy_data.txt"
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(sample_data)
    
    # å¤„ç†æ•°æ®
    processor = FinancialDataProcessor(
        sequence_length=180,
        prediction_horizon=7,
        trading_horizon=20,  # ç­–ç•¥éœ€è¦20å¤©åºåˆ—
        normalize=True,
        enable_trading_strategy=True,
        sliding_window=True
    )
    
    # è¯»å–å¹¶å¤„ç†æ•°æ®
    with open(temp_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    data_list = []
    for line in lines:
        if line.strip():
            parsed = processor.parse_data_line(line)
            if parsed:
                data_list.append(parsed)
    
    if not data_list:
        raise ValueError("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•æ•°æ®")
    
    # è½¬æ¢ä¸ºDataFrame
    import pandas as pd
    df = pd.DataFrame(data_list)
    df = processor.add_time_encoding(df)
    processor.fit_normalizer(df)
    df = processor.normalize_features(df)
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£åºåˆ—
    features_list, _, _, next_day_returns = processor.create_sliding_window_sequences(df)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_file)
    
    return features_list, next_day_returns, processor


def train_strategy_network():
    """è®­ç»ƒç­–ç•¥ç½‘ç»œ"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒGRUç­–ç•¥ç½‘ç»œ...")
    print("ğŸ’¡ ç‰¹ç‚¹: åŸºäºé¢„è®­ç»ƒä»·æ ¼ç½‘ç»œ + ç›¸å¯¹åŸºå‡†æ”¶ç›Š + é£é™©æˆæœ¬ + æœºä¼šæˆæœ¬")
    
    # 1. åŠ è½½é¢„è®­ç»ƒä»·æ ¼ç½‘ç»œ
    try:
        price_network, price_config = load_pretrained_price_network('best_price_network.pth')
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°é¢„è®­ç»ƒä»·æ ¼ç½‘ç»œ!")
        print("ğŸ“‹ è¯·å…ˆè¿è¡Œ: python train_price_network.py")
        return
    
    # 2. åˆ›å»ºç­–ç•¥è®­ç»ƒæ•°æ®
    features_list, next_day_returns, processor = create_strategy_dataset()
    
    print(f"ğŸ“Š ç­–ç•¥æ•°æ®å½¢çŠ¶:")
    print(f"  - ç‰¹å¾åºåˆ—: {features_list.shape}")      # [n_sequences, 20, 180, 11]
    print(f"  - æ¬¡æ—¥æ”¶ç›Š: {next_day_returns.shape}")    # [n_sequences, 20]
    
    # 3. æ•°æ®åˆ†å‰²
    n_sequences = features_list.shape[0]
    train_size = int(0.8 * n_sequences)
    
    train_features = features_list[:train_size]
    train_returns = next_day_returns[:train_size]
    
    val_features = features_list[train_size:]
    val_returns = next_day_returns[train_size:]
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"  - è®­ç»ƒåºåˆ—: {len(train_features)} ä¸ª")
    print(f"  - éªŒè¯åºåˆ—: {len(val_features)} ä¸ª")
    
    # 4. åˆ›å»ºç­–ç•¥ç½‘ç»œ
    strategy_config = ModelConfigs.small()
    
    # ç­–ç•¥ç½‘ç»œé…ç½®
    strategy_config.enable_stateful_training = True
    strategy_config.strategy_state_dim = 128
    strategy_config.state_update_method = 'gru'
    strategy_config.position_method = 'gumbel_softmax'
    strategy_config.d_model = price_config.d_model  # ä¸ä»·æ ¼ç½‘ç»œä¿æŒä¸€è‡´
    
    # æŸå¤±æƒé‡
    strategy_config.relative_return_weight = 1.0
    strategy_config.risk_cost_weight = 0.2
    strategy_config.opportunity_cost_weight = 0.1
    
    strategy_network = GRUStrategyNetwork(strategy_config)
    
    print(f"ğŸ—ï¸ ç­–ç•¥ç½‘ç»œåˆ›å»º:")
    print(f"  - å‚æ•°æ•°é‡: {sum(p.numel() for p in strategy_network.parameters()):,}")
    print(f"  - ç­–ç•¥çŠ¶æ€ç»´åº¦: {strategy_config.strategy_state_dim}")
    print(f"  - çŠ¶æ€æ›´æ–°æ–¹æ³•: {strategy_config.state_update_method}")
    
    # 5. åˆ›å»ºæŸå¤±å‡½æ•°
    market_classifier = create_market_classifier(strategy_config)
    strategy_loss = StrategyLoss(
        market_classifier=market_classifier,
        relative_return_weight=strategy_config.relative_return_weight,
        risk_cost_weight=strategy_config.risk_cost_weight,
        opportunity_cost_weight=strategy_config.opportunity_cost_weight
    )
    
    # 6. åˆ›å»ºè®­ç»ƒæµæ°´çº¿
    training_pipeline = StrategyTrainingPipeline(
        price_network=price_network,
        strategy_network=strategy_network,
        strategy_loss=strategy_loss
    )
    
    # 7. è®¾ç½®ä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ–ç­–ç•¥ç½‘ç»œï¼‰
    optimizer = optim.AdamW(
        strategy_network.parameters(),  # åªä¼˜åŒ–ç­–ç•¥ç½‘ç»œ
        lr=strategy_config.learning_rate * 0.5,  # ç­–ç•¥ç½‘ç»œç”¨è¾ƒå°å­¦ä¹ ç‡
        weight_decay=strategy_config.weight_decay,
        betas=(strategy_config.beta1, strategy_config.beta2)
    )
    
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=20, eta_min=1e-6
    )
    
    # 8. è®­ç»ƒå¾ªç¯
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    price_network.to(device)
    strategy_network.to(device)
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    print("ğŸ“ˆ å¼€å§‹ç­–ç•¥ç½‘ç»œè®­ç»ƒ...")
    
    num_epochs = 20
    best_val_return = float('-inf')
    batch_size = 2  # ç­–ç•¥è®­ç»ƒä½¿ç”¨å°æ‰¹æ¬¡
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        strategy_network.train()
        train_metrics = {
            'total_loss': 0.0,
            'relative_return_loss': 0.0,
            'risk_cost': 0.0,
            'opportunity_cost': 0.0,
            'mean_cumulative_return': 0.0,
            'mean_sharpe_ratio': 0.0
        }
        
        # åˆ›å»ºè®­ç»ƒæ‰¹æ¬¡
        train_batch_data = []
        for i in range(0, len(train_features), batch_size):
            end_idx = min(i + batch_size, len(train_features))
            train_batch_data.append({
                'financial_data': train_features[i:end_idx],
                'next_day_returns': train_returns[i:end_idx]
            })
        
        for batch_idx, batch_data in enumerate(train_batch_data):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            for key in batch_data:
                batch_data[key] = batch_data[key].to(device)
            
            optimizer.zero_grad()
            
            # è®­ç»ƒæ­¥éª¤
            loss_dict = training_pipeline.train_step(batch_data)
            
            # åå‘ä¼ æ’­
            loss_tensor = loss_dict['loss_tensor']
            loss_tensor.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(strategy_network.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç´¯ç§¯æŒ‡æ ‡
            for key in train_metrics:
                if key in loss_dict:
                    train_metrics[key] += loss_dict[key]
            
            # æ‰“å°è¿›åº¦
            if (batch_idx + 1) % 10 == 0:
                print(f"  Batch {batch_idx+1}/{len(train_batch_data)}: "
                      f"Loss={loss_dict['total_loss']:.6f}, "
                      f"Return={loss_dict['mean_cumulative_return']:+.4f}, "
                      f"Sharpe={loss_dict['mean_sharpe_ratio']:.4f}")
        
        # éªŒè¯é˜¶æ®µ
        strategy_network.eval()
        val_metrics = {
            'total_loss': 0.0,
            'relative_return_loss': 0.0,
            'risk_cost': 0.0,
            'opportunity_cost': 0.0,
            'mean_cumulative_return': 0.0,
            'mean_sharpe_ratio': 0.0
        }
        
        # åˆ›å»ºéªŒè¯æ‰¹æ¬¡
        val_batch_data = []
        for i in range(0, len(val_features), batch_size):
            end_idx = min(i + batch_size, len(val_features))
            val_batch_data.append({
                'financial_data': val_features[i:end_idx],
                'next_day_returns': val_returns[i:end_idx]
            })
        
        for batch_data in val_batch_data:
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            for key in batch_data:
                batch_data[key] = batch_data[key].to(device)
            
            # éªŒè¯æ­¥éª¤
            loss_dict = training_pipeline.validate_step(batch_data)
            
            # ç´¯ç§¯æŒ‡æ ‡
            for key in val_metrics:
                if key in loss_dict:
                    val_metrics[key] += loss_dict[key]
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        for key in train_metrics:
            train_metrics[key] /= len(train_batch_data)
        for key in val_metrics:
            val_metrics[key] /= len(val_batch_data)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['mean_cumulative_return'] > best_val_return:
            best_val_return = val_metrics['mean_cumulative_return']
            torch.save({
                'strategy_model_state_dict': strategy_network.state_dict(),
                'price_model_path': 'best_price_network.pth',
                'config': strategy_config,
                'epoch': epoch,
                'val_return': best_val_return
            }, 'best_strategy_network.pth')
        
        # æ‰“å°epochç»“æœ
        print(f"\nEpoch {epoch+1:2d}/{num_epochs}:")
        print(f"  è®­ç»ƒ - æŸå¤±: {train_metrics['total_loss']:.6f}, "
              f"ç´¯è®¡æ”¶ç›Š: {train_metrics['mean_cumulative_return']:+.4f}, "
              f"å¤æ™®æ¯”ç‡: {train_metrics['mean_sharpe_ratio']:+.4f}")
        print(f"  éªŒè¯ - æŸå¤±: {val_metrics['total_loss']:.6f}, "
              f"ç´¯è®¡æ”¶ç›Š: {val_metrics['mean_cumulative_return']:+.4f}, "
              f"å¤æ™®æ¯”ç‡: {val_metrics['mean_sharpe_ratio']:+.4f}")
        print(f"  å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.2e}")
    
    print("âœ… ç­–ç•¥ç½‘ç»œè®­ç»ƒå®Œæˆ!")
    
    # 9. æµ‹è¯•æœ€ä½³æ¨¡å‹
    print("\nğŸ”® æµ‹è¯•æœ€ä½³ç­–ç•¥ç½‘ç»œ...")
    checkpoint = torch.load('best_strategy_network.pth')
    strategy_network.load_state_dict(checkpoint['strategy_model_state_dict'])
    strategy_network.eval()
    
    # ä½¿ç”¨ä¸€ä¸ªéªŒè¯æ‰¹æ¬¡è¿›è¡Œæµ‹è¯•
    if val_batch_data:
        test_batch = val_batch_data[0]
        for key in test_batch:
            test_batch[key] = test_batch[key].to(device)
        
        loss_dict = training_pipeline.validate_step(test_batch)
        
        print(f"ğŸ“Š æœ€ä½³ç­–ç•¥ç½‘ç»œæ€§èƒ½:")
        print(f"  - ç´¯è®¡æ”¶ç›Šç‡: {loss_dict['mean_cumulative_return']:+.4f} ({loss_dict['mean_cumulative_return']*100:+.2f}%)")
        print(f"  - å¤æ™®æ¯”ç‡: {loss_dict['mean_sharpe_ratio']:+.4f}")
        print(f"  - æœ€å¤§å›æ’¤: {loss_dict['mean_max_drawdown']:.4f} ({loss_dict['mean_max_drawdown']*100:.2f}%)")
        print(f"  - ç›¸å¯¹æ”¶ç›ŠæŸå¤±: {loss_dict['relative_return_loss']:.6f}")
        print(f"  - é£é™©æˆæœ¬: {loss_dict['risk_cost']:.6f}")
        print(f"  - æœºä¼šæˆæœ¬: {loss_dict['opportunity_cost']:.6f}")
    
    print(f"\nğŸ’¾ ç­–ç•¥ç½‘ç»œå·²ä¿å­˜åˆ°: best_strategy_network.pth")
    print(f"ğŸ‰ ä¸¤é˜¶æ®µè®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“‹ ç°åœ¨å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹å’Œäº¤æ˜“")


if __name__ == "__main__":
    train_strategy_network()
